
## Project Plan - Faces

### Background ([paper](https://arxiv.org/pdf/2110.08935.pdf) & [repo](https://github.com/ostadabbas/Infant-Facial-Landmark-Detection-and-Tracking))
The ACLab created a new dataset of infant facial landmarks to be used for machine learning applications. The main take-aways from the paper are:
* The ACLab created infanface dataset (train and test, with 410 images, 68 landmarks, with pose attributes)
* They showed that existing deep learning algorithms for `image -> landmark coordinates` have a high error rate on the baby images (~22%)
* They produced (primarily) 2 modified models: 
    * 1 HrNet trained on the union of the adult and baby images with some rotation augmentation applied to some of the training data
    * 1 HrNet that is first pre-trained on the adult faces, and then fine-tuned on the baby faces, with some rotation augmentation also added
* Both these models preformed comparably well with ~2% error
* The main two steps for producing landmarks are:
  1. Generate a bounding box from the original image.
  2. Estimate landmarks from the bounding box.
  Existing models perform well on step 1, but fails on step 2. Wan’s paper is trying to fill the gap in step 2.

Other interesting things:
* They increased "size" of dataset by doing augmentations (rotations) of the images and random zooming?
* They do not "do anything" with the landmarks themselves, the paper is focused on using deep learning to do `image -> landmark coordinates` successfully with babies
    * However, there is a figure (fig 4) that plots a t-SNE dimensionally reduced HrNet representation of each image (adult and baby), showing that the HrNet model represents the baby and adult images differently. This figure is simply used to show the "domain gap" that the paper is trying to address. It is interesting that the model that fails accurately landmark the baby faces still does treat adult and baby faces differently?
        * t-SNE for improved HrNet model?

### Project Goal
Use classical machine learning techniques to classify adult vs infant faces using facial landmark data generated by the ACLab (InAnFace and 300W data)

Sub-goals: (roles and responsibilities)
* The idea here is to generally break up the tasks so that we all have the space to work on a few things. Then we can all come together and review our approaches and do any tweaking/fine tuning. For some of these, it might be nice to have someone primarily "own" the goal even though we will all be involved (like the checkins, website, etc).

1. Decide how to deal with the class imbalance between the adult and infant data **Sophia**
  * Learning curve (as we grow training set, how do diff models respond)? **Jesse** Which models are more biased towards inbalanced data? Which preformance metrics should be used per model?
2. Decide on what transformations/preprocessing of the landmarks to do **Jesse** **Zongyu**
  * Perhaps run the models with and without the updated landmarks?
3. Test out several ML classifiers
  * Create executable (from command line) and reproducible code/results & upload to repository
  * Keep track of what choices are made, such as:
    * Dimensional reduction (or not) 
      * fwd feature selection? 
    * Which hyper-parameters are chosen (and why)
    * What works/doesn’t work (and why)
      * Even if model is “bad”, still useful to know
  * Classifier ideas
    1. Logistic regression **Sophia**
    2. Naive bayes / discriminate analysis **Connor**
    3. SVC **Zongyu**
    4. Decision tree **Sophia**
    5. Random Forests 
    6. More ideas?
4. Project-check in 
5. Stakeholder feedback on prototype (incooperate)
6. Create simple website outlining our chosen ML methods and results **Sophia**
7. Final stakeholder feedback session? (incooperate)

### Timeline

* 22 Nov: "official" project check in
  * demonstrated progress on the project goals presented with a walk-through of the project repo
  * should include a submission in canvas with the url of a "checkin" branch in the project repo
* 28 Nov?: first stakeholder feedback session **we need to decide this asap**
* 4 Dec: project prototype due 
  * submitted in canvas as the URL of a "prototype" branch of the project repo
* 5 Dec?: final stakeholder feedback session
* 7 Dec: main branch of project is ready to go, feedback is implemented
* 8 Dec: project presentations
  * 9-minute presentations with 2-minute Q&A
* 15 Dec: final submission, feedback from presentation session is implemented
  * submitted in canvas as a "final" branch of the project repo


### Obstacles and Challenges
Place to record encountered and/or anticipated obstacles and challenges.

* The data is imbalanced in shape, there is roughly 3000 adult data points but only 400 infant data points
* Some of the preprocessing steps are tricky without 3D face meshes? 
* What should we use as predictors?
  * Possible predictors:
    1. All 68 landmarks 
    2. Relationships between landmarks, like Geometric values. Eg. box width / box height, and min box size / interocular distance
* Ideally the bounding box should be derived from the original image, but that would demand performing Retinaface, another deep learning model. Instead we use the estimated landmarks to estimate the geometric values.

### HTML page 
Plans for HTML page that tells "the story" concisely for a general audience.

My thinking is to structure it somewhat like [this](https://ds5010.github.io/vaccines/).
* Brief into explaining the project goal & concise results (which models worked and didn't work)
* Visuals and concise description (analysis) that clearly show the success/failure of the model in classifying adult/infant based on landmark data
  * sub-visuals and concise description that demonstrate why certain hyper-parameters were chosen, validation curves, or dimensional reduction used
* Short summary on pre-processing used to improve model accuracy
* Short summary on how the data was generated (using info from the paper)
* Acknowledgements


